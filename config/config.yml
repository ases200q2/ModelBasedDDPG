general:
  name:
  random_seed: 123
  updates_cycle_count: 10000
  episodes_per_update: 16
  model_updates_per_cycle: 40
#  model_updates_per_cycle: 400
  max_path_slack: 1.5
  gpu_usage: 0.01
  actor_gpu_usage: 0.01
  actor_processes: 8
#  actor_processes: 1
  write_train_summaries: 500

openrave_rl:
  action_step_size: 0.025
  segment_validity_step: 0.001
  goal_sensitivity: 0.04
  planner_iterations_start: 100
  planner_iterations_increase: 10
  planner_iterations_decrease: 1
  keep_alive_penalty: 0.01
  truncate_penalty: 0.05
#  shaping_coefficient: 0.01
  shaping_coefficient: 0.0
  challenging_trajectories_only: True
#  challenging_trajectories_only: False

model:
#  intial_samples_before_train: 128
  intial_samples_before_train: 512
  buffer_size: 1000000
#  batch_size: 128
  batch_size: 512
  gamma: 0.99
  potential_points: [2, 0., 0.075, 3, 0., 0.085, 4, -0.02, 0.05, 4, 0.005, 0.05, 5, 0.005, 0.035, 5, -0.02, 0.035]
  tau: 0.05
  consider_image: False
  consider_goal_pose: True
  random_action_probability: 0.2
  random_noise_std: 0.05
  use_reward_model: True
#  use_reward_model: False

test:
  test_every_cycles: 50
  number_of_episodes: 50

hindsight:
#  enable: False
  enable: True
#  type: 'goal'
  type: 'future'
  k: 4

curriculum:
  enable: False
#  enable: True
  initial_length: 0.1
  length_increments: 0.02
  success_rate_increase: 0.8
  minimal_episodes: 10

actor:
  learning_rate: 0.001
#  learning_rate: 0.0001
#  gradient_limit: 1.0
  gradient_limit: 0.0

action_predictor:
  layers: [200, 200, 200, 200]
#  layers: [64, 64, 64]
  activation: 'elu'
  tanh_preactivation_loss_coefficient: 1.0
#  tanh_preactivation_loss_coefficient: 0.0

critic:
  learning_rate: 0.001
#  learning_rate: 0.0001
#  gradient_limit: 10.0
  gradient_limit: 0.0
  layers_before_action: [200, 200]
  layers_after_action: [200, 200, 200]
#  layers_before_action: [64]
#  layers_after_action: [64, 64]
  activation: 'elu'
  l2_regularization_coefficient: 0.0
#  l2_regularization_coefficient: 0.0001

reward:
  learning_rate: 0.001
#  learning_rate: 0.0001
#  gradient_limit: 10.0
  gradient_limit: 0.0
  layers_before_action: [50, 50]
  layers_after_action: [50, 50]
  activation: 'elu'

termination:
  learning_rate: 0.001
#  learning_rate: 0.0001
#  gradient_limit: 10.0
  gradient_limit: 0.0
  layers_before_action: [50, 50]
  layers_after_action: [50, 50]
  activation: 'elu'


