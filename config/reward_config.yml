general:
  epochs: 5000
  save_every_epochs: 5
  gpu_usage: 0.1
#  scenario: 'no_obstacles'
#  scenario: 'simple'
  scenario: 'hard'
#  scenario: 'vision'

openrave_rl:
  action_step_size: 0.025
  segment_validity_step: 0.001
  goal_sensitivity: 0.04
  planner_iterations_start: 100
  planner_iterations_increase: 10
  planner_iterations_decrease: 1
  keep_alive_penalty: 0.01
  truncate_penalty: 0.05

model:
  batch_size: 10240
  potential_points: [2, 0., 0.075, 3, 0., 0.085, 4, -0.02, 0.05, 4, 0.005, 0.05, 5, 0.005, 0.035, 5, -0.02, 0.035]
  consider_image: False
  consider_goal_pose: True

reward:
#  initial_learn_rate: 0.001
  initial_learn_rate: 0.01
  decrease_learn_rate_after: 2000
#  decrease_learn_rate_after: 10000
  learn_rate_decrease_rate: 0.8
#  learning_rate: 0.0001
  gradient_limit: 5.0
#  gradient_limit: 0.0
  layers: [50, 50, 50]
#  layers: [100, 100, 100]
#  layers: [50, 50, 50, 50]
#  layers: [100, 100, 100, 100]
  l2_regularization_coefficient: 0.0001
  cross_entropy_coefficient: 1.0
  activation: 'elu'


